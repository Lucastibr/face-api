<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Reconhecimento Facial</title>
  <!-- Carregar Face API.js via CDN -->
  <script defer src="face-api.js"></script>
  <style>
    video, canvas {
      display: block;
      margin: auto;
    }
  </style>
</head>
<body>
  <h1 style="text-align: center;">Detecção de Faces</h1>
  <video id="video" width="720" height="560" autoplay muted></video>
  <canvas id="overlay" width="720" height="560"></canvas>

  <script>
    // Esperar até que o DOM esteja carregado para garantir que face-api.js foi carregado
    document.addEventListener("DOMContentLoaded", async function () {
      if (typeof faceapi === 'undefined') {
        console.error('Face API.js não foi carregado corretamente.');
        return;
      }

      console.log('Face API.js carregado com sucesso.');

      // Função para carregar os modelos de reconhecimento facial
      async function loadModels() {
        try {
          await faceapi.nets.tinyFaceDetector.loadFromUri('/models'); // Certifique-se de que os modelos estão em 'public/models'
          console.log('Modelos carregados!');
        } catch (error) {
          console.error('Erro ao carregar os modelos:', error);
        }
      }

      // Inicializar a câmera e carregar os modelos
      async function startVideo() {
        const video = document.getElementById('video');
        await loadModels();

        // Capturar vídeo da câmera
        navigator.mediaDevices.getUserMedia({ video: {} })
          .then(stream => video.srcObject = stream)
          .catch(err => console.error('Erro ao acessar a câmera:', err));
      }

      // Detectar rostos em tempo real
      async function detectFaces() {
        const video = document.getElementById('video');
        const overlay = document.getElementById('overlay');
        const displaySize = { width: video.width, height: video.height };

        faceapi.matchDimensions(overlay, displaySize);

        // Processar frames de vídeo
        setInterval(async () => {
          const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions());
          const resizedDetections = faceapi.resizeResults(detections, displaySize);
          const context = overlay.getContext('2d');
          context.clearRect(0, 0, overlay.width, overlay.height);

          // Desenhar caixas ao redor das faces detectadas
          faceapi.draw.drawDetections(overlay, resizedDetections);

          // Se detectar um rosto, salvar a imagem
          if (detections.length > 0) {
            console.log('Rosto detectado, salvando...');
            saveFace(video);
          }
        }, 1000);
      }

      // Função para capturar e salvar a imagem do vídeo
      async function saveFace(video) {
        const canvas = document.createElement('canvas');
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        const context = canvas.getContext('2d');
        context.drawImage(video, 0, 0, canvas.width, canvas.height);

        // Converter a imagem para um blob
        const blob = await new Promise(resolve => canvas.toBlob(resolve, 'image/jpeg'));

        // Enviar a imagem para o servidor
        const formData = new FormData();
        formData.append('image', blob, 'face.jpg');

        fetch('http://localhost:3000/upload', {
          method: 'POST',
          body: formData,
        })
        .then(response => response.json())
        .then(data => console.log(data))
        .catch(err => console.error('Erro ao enviar a imagem:', err));
      }

      // Iniciar a captura de vídeo e a detecção de faces
      startVideo().then(detectFaces);
    });
  </script>
</body>
</html>
